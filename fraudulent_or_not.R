###########################
### Fraudulent or not   ###
### Sari Vesiluoma 2019 ###
###########################

# Ensuring having required libraries
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
library(tidyverse)
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
library(caret)
if(!require(readr)) install.packages("readr", repos = "http://cran.us.r-project.org")
library(readr)
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
library(knitr)
if(!require(MASS)) install.packages("MASS", repos = "http://cran.us.r-project.org")
library(MASS)
if(!require(gam)) install.packages("gam", repos = "http://cran.us.r-project.org")
library(gam)
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
library(randomForest)

# Synthetic Financial Datasets For Fraud Detection
# Synthetic datasets generated by the PaySim mobile money simulator
# https://www.kaggle.com/ntnu-testimon/paysim1
# https://www.kaggle.com/ntnu-testimon/paysim1/download#PS_20174392719_1491204439457_log.csv
# I have downloaded the file using the above links and unzipped it to my local git directory

# Read the dataset from unzipped file at the same folder where this R script is
fraud_or_not <- read_csv("PS_20174392719_1491204439457_log.csv")

# What are the dimensions of this data?
dim(fraud_or_not)

# Look the summary,structure and first lines of this data
summary(fraud_or_not)
str(fraud_or_not)
fraud_or_not %>% head()

# Showing the feature explanations as a table
explanations <- data.frame(feature = "step", expl = "maps a unit of time in the real world. In this case 1 step is 1 hour of time. Total steps 744 (30 days simulation).")
explanations <- bind_rows(explanations, data_frame(feature = "type", expl = "CASH-IN, CASH-OUT, DEBIT, PAYMENT and TRANSFER."))
explanations <- bind_rows(explanations, data_frame(feature = "amount", expl = "amount of the transaction in local currency."))
explanations <- bind_rows(explanations, data_frame(feature = "nameOrig", expl = "customer who started the transaction"))
explanations <- bind_rows(explanations, data_frame(feature = "oldbalanceOrg", expl = "initial balance before the transaction"))
explanations <- bind_rows(explanations, data_frame(feature = "newbalanceOrig", expl = "new balance after the transaction"))
explanations <- bind_rows(explanations, data_frame(feature = "nameDest", expl = "customer who is the recipient of the transaction"))
explanations <- bind_rows(explanations, data_frame(feature = "oldbalanceDest", expl = "initial balance recipient before the transaction. Note that there is not information for customers that start with M (Merchants)."))
explanations <- bind_rows(explanations, data_frame(feature = "newbalanceDest", expl = "new balance recipient after the transaction. Note that there is not information for customers that start with M (Merchants)."))
explanations <- bind_rows(explanations, data_frame(feature = "isFraud", expl = "This is the transactions made by the fraudulent agents inside the simulation. In this specific dataset the fraudulent behavior of the agents aims to profit by taking control or customers accounts and try to empty the funds by transferring to another account and then cashing out of the system."))
explanations <- bind_rows(explanations, data_frame(feature = "isFlaggedFraud", expl = "The business model aims to control massive transfers from one account to another and flags illegal attempts. An illegal attempt in this dataset is an attempt to transfer more than 200.000 in a single transaction."))
kable(explanations, caption = "Explanations of the features")

# Study the specialties of the data
# What amount of the rows are fraudulent
mean(fraud_or_not$isFraud)
# Percentage of non-fraudulent transactions
(1-mean(fraud_or_not$isFraud))*100

# Amount of transactions per type as histogram
fraud_or_not %>% ggplot(aes(type , fill = type)) + geom_bar()

# Amount of fraudulent transactions per type as histogram
fraud_or_not %>% filter(isFraud==1) %>% 
  ggplot(aes(type , fill = type)) + geom_bar()

# Clearing away all other types than CASH_OUT and TRANSFER because in the other there is no fraudulent transactions
fraud_or_not <- fraud_or_not %>% filter(type == "CASH_OUT" | type == "TRANSFER")
table(fraud_or_not$type)

# Creating training and test sets
set.seed(1234, sample.kind = "Rounding")
test_index <- createDataPartition(y = fraud_or_not$isFraud, times = 1,
                                  p = 0.2, list = FALSE)
train_set <- fraud_or_not[-test_index,]
test_set <- fraud_or_not[test_index,]

# Checking the dimensions and prevalence of fraud in these sets
dim(train_set)
mean(train_set$isFraud == "1")
dim(test_set)
mean(test_set$isFraud == "1")

# Algorithm 1: quess that none of the transactions are fraud
# Splitting the training and test data to X and y to make it easier to use those
y_train <- factor(train_set$isFraud)
X_train <- train_set[,which(names(train_set) != "isFraud")]
y_test <- factor(test_set$isFraud)
X_test <- test_set[,which(names(test_set) != "isFraud")]
# Define mu_hat as a predition of no fraudulent transactions
mu_hat <- factor(replicate(length(y_test), 0))
# Check the results with a confusionMatrix - ensure the same levels to be used
cm <- confusionMatrix(data = mu_hat, reference = y_test)
cm
# Store the results of this algorithm
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(mu_hat, y_test, positive= "1")
algorithm_results <- data.frame(method="1: Assume none is fraud", 
                                accuracy=acc, specificity=specif)

#####  THE PDF INCLUDES ROWS THIS FAR

# Algorithm 2: Logistic regression model
# Training & predicting
train_glm <- train(X_train, y_train, method = "glm")
glm_preds <- factor(predict(train_glm, X_test))
# Define accuracy and specificity
cm <- confusionMatrix(data = glm_preds,reference = y_test)
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(glm_preds, y_test, positive= "1")
# Store the results of this algorithm
algorithm_results <- bind_rows(algorithm_results, 
                               data_frame(method="2: Logistic regression", 
                                accuracy=acc, 
                                specificity=specif))

# Algorithm 3: LDA
# Training & predicting
train_lda <- train(X_train, y_train, method = "lda")
lda_preds <- factor(predict(train_lda, X_test))
# Define accuracy and specificity
cm <- confusionMatrix(data = lda_preds,reference = y_test)
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(lda_preds, y_test, positive= "1")
# Store the results of this algorithm
algorithm_results <- bind_rows(algorithm_results, 
                               data_frame(method="3: LDA", 
                                          accuracy=acc, 
                                          specificity=specif))

# Algorithm 4: QDA
# Training & predicting
train_qda <- train(X_train, y_train, method = "qda")
qda_preds <- factor(predict(train_qda, X_test))
# Define accuracy and specificity
cm <- confusionMatrix(data = qda_preds,reference = y_test)
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(qda_preds, y_test, positive= "1")
# Store the results of this algorithm
algorithm_results <- bind_rows(algorithm_results, 
                               data_frame(method="4: QDA", 
                                          accuracy=acc, 
                                          specificity=specif))

# Algorithm 5: Loess
# Training & predicting
train_loess <- train(X_train, y_train, method = "gamLoess")
loess_preds <- factor(predict(train_loess, X_test))
# Define accuracy and specificity
cm <- confusionMatrix(data = loess_preds,reference = y_test)
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(loess_preds, y_test, positive= "1")
# Store the results of this algorithm
algorithm_results <- bind_rows(algorithm_results, 
                               data_frame(method="5: Loess", 
                                          accuracy=acc, 
                                          specificity=specif))

# Algorithm 6: K-nearest neighbors
# Training & predicting - trials with k values from 3 to 21 (step: 2)
set.seed(1234, smple.kind = "Rounding")
tuning <- data.frame(k=seq(3, 21, 2))
train_knn <- train(X_train, y_train, method = "knn", tuneGrid = tuning)
train_knn$ÊbestTune
knn_preds <- factor(predict(train_knn, X_test))
# Define accuracy and specificity
cm <- confusionMatrix(data = knn_preds,reference = y_test)
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(knn_preds, y_test, positive= "1")
# Store the results of this algorithm
algorithm_results <- bind_rows(algorithm_results, 
                               data_frame(method="6: knn", 
                                          accuracy=acc, 
                                          specificity=specif))

# Algorithm 7: Random forest
# Training & predicting - trials with mtry values from 3 to 9 (step: 2)
set.seed(1234, smple.kind = "Rounding")
tuning <- data.frame(mtry=seq(3, 9, 2))
train_rf <- train(X_train, y_train, method = "rf", tuneGrid = tuning, importance=TRUE)
train_rf$ÊbestTune
rf_preds <- factor(predict(train_rf, X_test))
# Define accuracy and specificity
cm <- confusionMatrix(data = rf_preds,reference = y_test)
acc <- cm$overall[['Accuracy']]
specif <- sensitivity(rf_preds, y_test, positive= "1")
# Store the results of this algorithm
algorithm_results <- bind_rows(algorithm_results, 
                               data_frame(method="7: Random forest", 
                                          accuracy=acc, 
                                          specificity=specif))





